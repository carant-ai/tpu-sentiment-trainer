Using the latest cached version of the dataset since thonyyy/indonesian_sentiment_dataset_v1 couldn't be found on the Hugging Face Hub
WARNING:datasets.load:Using the latest cached version of the dataset since thonyyy/indonesian_sentiment_dataset_v1 couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/hikar/.cache/huggingface/datasets/thonyyy___indonesian_sentiment_dataset_v1/default/0.0.0/1c2bd788a03c5ae8e92d1e4fb259ccd2704ec379 (last modified on Thu May  9 09:43:20 2024).
WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'default' at /home/hikar/.cache/huggingface/datasets/thonyyy___indonesian_sentiment_dataset_v1/default/0.0.0/1c2bd788a03c5ae8e92d1e4fb259ccd2704ec379 (last modified on Thu May  9 09:43:20 2024).
Using the latest cached version of the dataset since thonyyy/english_sentiment_dataset_v1 couldn't be found on the Hugging Face Hub
WARNING:datasets.load:Using the latest cached version of the dataset since thonyyy/english_sentiment_dataset_v1 couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/hikar/.cache/huggingface/datasets/thonyyy___english_sentiment_dataset_v1/default/0.0.0/73438c180c8dc9edce83e4995625413b66dda6a6 (last modified on Thu May  9 08:43:14 2024).
WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'default' at /home/hikar/.cache/huggingface/datasets/thonyyy___english_sentiment_dataset_v1/default/0.0.0/73438c180c8dc9edce83e4995625413b66dda6a6 (last modified on Thu May  9 08:43:14 2024).
/home/hikar/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Read model hyperparameter from .env
Loading dataset from huggingface hub
Loading model to finetune
Take 5.0 percent data as evaluation dataset
Map:   0%|          | 0/11041394 [00:00<?, ? examples/s]Map:   0%|          | 0/11041394 [00:00<?, ? examples/s]Map:   0%|          | 0/11041394 [00:00<?, ? examples/s]
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    train_dataset = train_dataset.map(tokenize_function, batched = True, batch_size = 100000, remove_columns = col_names)
  File "/home/hikar/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 602, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/hikar/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 567, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/hikar/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 3156, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/hikar/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 3547, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/hikar/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 3416, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "train.py", line 71, in tokenize_function
    result = tokenizer(
  File "/home/hikar/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2858, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/hikar/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2944, in _call_one
    return self.batch_encode_plus(
  File "/home/hikar/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 3135, in batch_encode_plus
    return self._batch_encode_plus(
TypeError: _batch_encode_plus() got an unexpected keyword argument 'return_tensor'
